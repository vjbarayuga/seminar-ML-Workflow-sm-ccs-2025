Open VS Code

Create a new file: iris_ml_workflow.py

Make sure you have the required packages installed:
pip install pandas seaborn matplotlib scikit-learn


Start constructing the code:

# 1Ô∏è‚É£ Import Libraries	Tools for data handling, modeling, and visualization
# 2Ô∏è‚É£ Load/Generate Dataset	Real datasets or synthetic data for controlled experiments
# 3Ô∏è‚É£ Exploratory Data Analysis (EDA)	Understand the data: shape, features, correlations
# 4Ô∏è‚É£ Preprocessing	Scaling, encoding, cleaning
# 5Ô∏è‚É£ Train-Test Split	Separate data for learning and testing
# 6Ô∏è‚É£ Model Selection	Choose the right algorithm
# 7Ô∏è‚É£ Training	Fit model to training data
# 8Ô∏è‚É£ Evaluation	Accuracy, precision, recall, MSE, R¬≤, etc.
# 9Ô∏è‚É£ Visualization	Optional, but helps in interpretation

# iris_ml_workflow.py

# Step 1Ô∏è‚É£: Import Libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.decomposition import PCA

# Step 2Ô∏è‚É£: Load Dataset
iris = load_iris()

# Create a DataFrame
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['species'] = iris.target
df['species_name'] = df['species'].apply(lambda x: iris.target_names[x])

# Step 3Ô∏è‚É£: Exploratory Data Analysis (EDA)
print("üîç Dataset Summary:")
print(df.describe())
print("\nüîç Class Distribution:")
print(df['species_name'].value_counts())

# Optional: Pairplot for visualization
sns.pairplot(df, hue='species_name')
plt.title("Pairplot of Iris Dataset")
plt.show()

# Step 4Ô∏è‚É£: Preprocessing
X = df[iris.feature_names]
y = df['species']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 5Ô∏è‚É£: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# Step 6Ô∏è‚É£: Model Selection
model = LogisticRegression(max_iter=200)

# Step 7Ô∏è‚É£: Training
model.fit(X_train, y_train)

# Step 8Ô∏è‚É£: Evaluation
y_pred = model.predict(X_test)

print("\nüìä Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nüìà Classification Report:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# Step 9Ô∏è‚É£: Visualization (PCA)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(8, 5))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=df['species_name'], palette='Set2')
plt.title("üå∏ Iris Dataset - PCA Visualization")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.grid(True)
plt.show()
